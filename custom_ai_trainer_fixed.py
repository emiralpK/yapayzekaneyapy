import tkinter as tk
from tkinter import ttk, filedialog, scrolledtext, messagebox
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
from collections import Counter
import json
import os
import threading
import time
from datetime import datetime
import re

class CustomTokenizer:
    def __init__(self):
        self.word2idx = {"<PAD>": 0, "<UNK>": 1, "<START>": 2, "<END>": 3}
        self.idx2word = {0: "<PAD>", 1: "<UNK>", 2: "<START>", 3: "<END>"}
        self.word_freq = Counter()
        
    def fit(self, texts, min_freq=2):
        for text in texts:
            words = self.tokenize(text)
            self.word_freq.update(words)
        
        idx = len(self.word2idx)
        for word, freq in self.word_freq.items():
            if freq >= min_freq and word not in self.word2idx:
                self.word2idx[word] = idx
                self.idx2word[idx] = word
                idx += 1
    
    def tokenize(self, text):
        text = text.lower()
        text = re.sub(r'[^\w\s]', ' ', text)
        return text.split()
    
    def encode(self, text, max_len=128):
        tokens = self.tokenize(text)
        encoded = [self.word2idx.get(token, 1) for token in tokens]
        if len(encoded) < max_len:
            encoded += [0] * (max_len - len(encoded))
        else:
            encoded = encoded[:max_len]
        return encoded
    
    def decode(self, indices):
        words = []
        for idx in indices:
            if idx == 0:
                continue
            if idx == 3:
                break
            words.append(self.idx2word.get(idx, "<UNK>"))
        return " ".join(words)

class TextDataset(Dataset):
    def __init__(self, texts, tokenizer, seq_len=128):
        self.tokenizer = tokenizer
        self.seq_len = seq_len
        self.data = []
        
        for text in texts:
            encoded = tokenizer.encode(text, seq_len)
            if len(encoded) > 1:
                for i in range(len(encoded) - 1):
                    self.data.append((encoded[i], encoded[i + 1]))
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        x, y = self.data[idx]
        return torch.tensor(x), torch.tensor(y)

class QuantizedLinear(nn.Module):
    def __init__(self, in_features, out_features, bits=4):
        super().__init__()
        self.bits = bits
        self.scale = nn.Parameter(torch.ones(out_features))
        self.zero_point = nn.Parameter(torch.zeros(out_features))
        
        if bits == 2:
            self.qmin, self.qmax = -2, 1
        elif bits == 4:
            self.qmin, self.qmax = -8, 7
        else:
            self.qmin, self.qmax = -128, 127
            
        self.weight = nn.Parameter(torch.randn(out_features, in_features))
        self.bias = nn.Parameter(torch.zeros(out_features))
    
    def quantize(self, x):
        x = torch.clamp(x / self.scale.view(-1, 1) + self.zero_point.view(-1, 1), self.qmin, self.qmax)
        return torch.round(x)
    
    def dequantize(self, x):
        return (x - self.zero_point.view(-1, 1)) * self.scale.view(-1, 1)
    
    def forward(self, x):
        w_quant = self.quantize(self.weight)
        w_dequant = self.dequantize(w_quant)
        return torch.matmul(x, w_dequant.t()) + self.bias

class MiniTransformer(nn.Module):
    def __init__(self, vocab_size, embed_dim=128, hidden_dim=256, num_layers=2, bits=4):
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, embed_dim)
        self.pos_encoding = nn.Parameter(torch.randn(1, 512, embed_dim))
        
        self.layers = nn.ModuleList()
        for _ in range(num_layers):
            if bits in [2, 4]:
                self.layers.append(nn.ModuleDict({
                    'attn': QuantizedLinear(embed_dim, embed_dim, bits),
                    'ff1': QuantizedLinear(embed_dim, hidden_dim, bits),
                    'ff2': QuantizedLinear(hidden_dim, embed_dim, bits),
                    'norm1': nn.LayerNorm(embed_dim),
                    'norm2': nn.LayerNorm(embed_dim)
                }))
            else:
                self.layers.append(nn.ModuleDict({
                    'attn': nn.Linear(embed_dim, embed_dim),
                    'ff1': nn.Linear(embed_dim, hidden_dim),
                    'ff2': nn.Linear(hidden_dim, embed_dim),
                    'norm1': nn.LayerNorm(embed_dim),
                    'norm2': nn.LayerNorm(embed_dim)
                }))
        
        self.output = nn.Linear(embed_dim, vocab_size)
        self.dropout = nn.Dropout(0.1)
    
    def forward(self, x):
        seq_len = x.shape[1]
        x = self.embedding(x)
        x = x + self.pos_encoding[:, :seq_len, :]
        x = self.dropout(x)
        
        for layer in self.layers:
            # Self-attention
            attn_out = layer['attn'](layer['norm1'](x))
            x = x + self.dropout(attn_out)
            
            # Feed-forward
            ff_out = layer['ff2'](torch.relu(layer['ff1'](layer['norm2'](x))))
            x = x + self.dropout(ff_out)
        
        return self.output(x)

class AITrainerApp:
    def __init__(self, root):
        self.root = root
        self.root.title("ü§ñ Kendi AI'nƒ± Eƒüit - Ultra Modern")
        self.root.geometry("1400x800")
        
        # Deƒüi≈ükenler
        self.model = None
        self.tokenizer = CustomTokenizer()
        self.is_training = False
        self.loaded_texts = []
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # Stil ayarlarƒ±
        self.setup_styles()
        self.create_widgets()
        
    def setup_styles(self):
        style = ttk.Style()
        style.theme_use('clam')
        
        # Renkler
        self.colors = {
            'bg': '#1a1a2e',
            'fg': '#eee',
            'accent': '#00d4ff',
            'secondary': '#0f3460',
            'success': '#00ff88',
            'danger': '#ff0055',
            'warning': '#ffaa00'
        }
        
        self.root.configure(bg=self.colors['bg'])
        
        style.configure('Title.TLabel', font=('Segoe UI', 24, 'bold'), foreground=self.colors['accent'])
        style.configure('Heading.TLabel', font=('Segoe UI', 12, 'bold'), foreground=self.colors['fg'])
        style.configure('Modern.TButton', font=('Segoe UI', 10, 'bold'))
        
    def create_widgets(self):
        # Ana container
        main_container = tk.Frame(self.root, bg=self.colors['bg'])
        main_container.pack(fill=tk.BOTH, expand=True, padx=20, pady=20)
        
        # Ba≈ülƒ±k
        title_frame = tk.Frame(main_container, bg=self.colors['bg'])
        title_frame.pack(fill=tk.X, pady=(0, 20))
        
        title_label = tk.Label(title_frame, text="ü§ñ Kendi AI Modelini Olu≈ütur", 
                               font=('Segoe UI', 28, 'bold'), 
                               fg=self.colors['accent'], bg=self.colors['bg'])
        title_label.pack()
        
        gpu_info = "üéÆ GPU: " + ("CUDA Aktif (RTX 4070)" if torch.cuda.is_available() else "CPU Modu")
        gpu_label = tk.Label(title_frame, text=gpu_info, 
                             font=('Segoe UI', 10), 
                             fg=self.colors['success'] if torch.cuda.is_available() else self.colors['warning'], 
                             bg=self.colors['bg'])
        gpu_label.pack()
        
        # Notebook (sekmeler)
        self.notebook = ttk.Notebook(main_container)
        self.notebook.pack(fill=tk.BOTH, expand=True)
        
        # Eƒüitim sekmesi
        self.create_training_tab()
        
        # Sohbet sekmesi
        self.create_chat_tab()
        
        # Model bilgi sekmesi
        self.create_info_tab()
        
    def create_training_tab(self):
        train_frame = tk.Frame(self.notebook, bg=self.colors['secondary'])
        self.notebook.add(train_frame, text="üéì Eƒüitim")
        
        # Sol panel - Ayarlar
        left_panel = tk.Frame(train_frame, bg=self.colors['secondary'], width=400)
        left_panel.pack(side=tk.LEFT, fill=tk.BOTH, padx=10, pady=10)
        
        # Dosya y√ºkleme
        file_frame = tk.LabelFrame(left_panel, text="üìÅ Veri Y√ºkleme", 
                                  font=('Segoe UI', 11, 'bold'),
                                  fg=self.colors['fg'], bg=self.colors['secondary'])
        file_frame.pack(fill=tk.X, pady=10)
        
        self.load_btn = tk.Button(file_frame, text="üìÇ Dosya Se√ß (.txt)", 
                                 command=self.load_file,
                                 font=('Segoe UI', 10, 'bold'),
                                 bg=self.colors['accent'], fg='white',
                                 cursor='hand2')
        self.load_btn.pack(pady=10, padx=10)
        
        self.file_info = tk.Label(file_frame, text="Dosya y√ºklenmedi", 
                                 font=('Segoe UI', 9),
                                 fg=self.colors['warning'], bg=self.colors['secondary'])
        self.file_info.pack(pady=5)
        
        # Model ayarlarƒ±
        model_frame = tk.LabelFrame(left_panel, text="‚öôÔ∏è Model Ayarlarƒ±", 
                                   font=('Segoe UI', 11, 'bold'),
                                   fg=self.colors['fg'], bg=self.colors['secondary'])
        model_frame.pack(fill=tk.X, pady=10)
        
        # Bit se√ßimi
        tk.Label(model_frame, text="Quantization:", 
                font=('Segoe UI', 10),
                fg=self.colors['fg'], bg=self.colors['secondary']).pack(anchor=tk.W, padx=10, pady=5)
        
        self.bit_var = tk.StringVar(value="4")
        bit_frame = tk.Frame(model_frame, bg=self.colors['secondary'])
        bit_frame.pack(pady=5)
        
        for bits in ["2-bit (En K√º√ß√ºk)", "4-bit (Dengeli)", "8-bit (Kaliteli)"]:
            rb = tk.Radiobutton(bit_frame, text=bits, 
                               variable=self.bit_var, 
                               value=bits.split('-')[0],
                               font=('Segoe UI', 9),
                               fg=self.colors['fg'], bg=self.colors['secondary'],
                               selectcolor=self.colors['secondary'])
            rb.pack(anchor=tk.W)
        
        # Epoch sayƒ±sƒ±
        tk.Label(model_frame, text="Epoch Sayƒ±sƒ±:", 
                font=('Segoe UI', 10),
                fg=self.colors['fg'], bg=self.colors['secondary']).pack(anchor=tk.W, padx=10, pady=5)
        
        self.epoch_var = tk.IntVar(value=10)
        self.epoch_scale = tk.Scale(model_frame, from_=1, to=50, 
                                   orient=tk.HORIZONTAL,
                                   variable=self.epoch_var,
                                   bg=self.colors['secondary'], fg=self.colors['fg'],
                                   highlightthickness=0)
        self.epoch_scale.pack(fill=tk.X, padx=10)
        
        # Eƒüitim butonu
        self.train_btn = tk.Button(left_panel, text="üöÄ Eƒüitimi Ba≈ülat", 
                                  command=self.start_training,
                                  font=('Segoe UI', 12, 'bold'),
                                  bg=self.colors['success'], fg='white',
                                  height=2, cursor='hand2')
        self.train_btn.pack(fill=tk.X, pady=20, padx=10)
        
        # Saƒü panel - Log ve ilerleme
        right_panel = tk.Frame(train_frame, bg=self.colors['secondary'])
        right_panel.pack(side=tk.RIGHT, fill=tk.BOTH, expand=True, padx=10, pady=10)
        
        # ƒ∞lerleme √ßubuƒüu
        progress_frame = tk.LabelFrame(right_panel, text="üìä ƒ∞lerleme", 
                                     font=('Segoe UI', 11, 'bold'),
                                     fg=self.colors['fg'], bg=self.colors['secondary'])
        progress_frame.pack(fill=tk.X, pady=10)
        
        self.progress_var = tk.DoubleVar()
        self.progress_bar = ttk.Progressbar(progress_frame, 
                                           variable=self.progress_var,
                                           maximum=100,
                                           length=400)
        self.progress_bar.pack(pady=10, padx=10, fill=tk.X)
        
        self.progress_label = tk.Label(progress_frame, text="Hazƒ±r", 
                                      font=('Segoe UI', 10),
                                      fg=self.colors['fg'], bg=self.colors['secondary'])
        self.progress_label.pack()
        
        # Log alanƒ±
        log_frame = tk.LabelFrame(right_panel, text="üìù Eƒüitim Loglarƒ±", 
                                font=('Segoe UI', 11, 'bold'),
                                fg=self.colors['fg'], bg=self.colors['secondary'])
        log_frame.pack(fill=tk.BOTH, expand=True, pady=10)
        
        self.log_text = scrolledtext.ScrolledText(log_frame, 
                                                 font=('Consolas', 9),
                                                 bg='#0a0a0a', fg=self.colors['success'],
                                                 height=15)
        self.log_text.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        
    def create_chat_tab(self):
        chat_frame = tk.Frame(self.notebook, bg=self.colors['secondary'])
        self.notebook.add(chat_frame, text="üí¨ Sohbet")
        
        # Sohbet alanƒ±
        chat_container = tk.Frame(chat_frame, bg=self.colors['secondary'])
        chat_container.pack(fill=tk.BOTH, expand=True, padx=20, pady=20)
        
        # Sohbet ge√ßmi≈üi
        self.chat_display = scrolledtext.ScrolledText(chat_container,
                                                     font=('Segoe UI', 11),
                                                     bg='#0a0a0a', fg=self.colors['fg'],
                                                     wrap=tk.WORD,
                                                     height=20)
        self.chat_display.pack(fill=tk.BOTH, expand=True)
        
        # Mesaj giri≈ü alanƒ±
        input_frame = tk.Frame(chat_container, bg=self.colors['secondary'])
        input_frame.pack(fill=tk.X, pady=10)
        
        self.message_entry = tk.Entry(input_frame,
                                     font=('Segoe UI', 11),
                                     bg=self.colors['bg'], fg=self.colors['fg'],
                                     insertbackground=self.colors['accent'])
        self.message_entry.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        self.message_entry.bind('<Return>', lambda e: self.send_message())
        
        self.send_btn = tk.Button(input_frame, text="üì§ G√∂nder",
                                command=self.send_message,
                                font=('Segoe UI', 10, 'bold'),
                                bg=self.colors['accent'], fg='white',
                                cursor='hand2')
        self.send_btn.pack(side=tk.RIGHT, padx=(10, 0))
        
    def create_info_tab(self):
        info_frame = tk.Frame(self.notebook, bg=self.colors['secondary'])
        self.notebook.add(info_frame, text="üìä Model Bilgileri")
        
        # Model istatistikleri
        stats_container = tk.Frame(info_frame, bg=self.colors['secondary'])
        stats_container.pack(fill=tk.BOTH, expand=True, padx=20, pady=20)
        
        self.stats_text = tk.Text(stats_container,
                                 font=('Consolas', 10),
                                 bg='#0a0a0a', fg=self.colors['accent'],
                                 height=20)
        self.stats_text.pack(fill=tk.BOTH, expand=True)
        
        # Butonlar
        btn_frame = tk.Frame(stats_container, bg=self.colors['secondary'])
        btn_frame.pack(fill=tk.X, pady=10)
        
        tk.Button(btn_frame, text="üíæ Modeli Kaydet",
                 command=self.save_model,
                 font=('Segoe UI', 10, 'bold'),
                 bg=self.colors['success'], fg='white',
                 cursor='hand2').pack(side=tk.LEFT, padx=5)
        
        tk.Button(btn_frame, text="üìÇ Model Y√ºkle",
                 command=self.load_model,
                 font=('Segoe UI', 10, 'bold'),
                 bg=self.colors['accent'], fg='white',
                 cursor='hand2').pack(side=tk.LEFT, padx=5)
        
    def load_file(self):
        file_path = filedialog.askopenfilename(
            title="Eƒüitim Dosyasƒ± Se√ß",
            filetypes=[("Text files", "*.txt"), ("All files", "*.*")]
        )
        
        if file_path:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # Metni c√ºmlelere b√∂l
                sentences = re.split(r'[.!?]+', content)
                self.loaded_texts = [s.strip() for s in sentences if len(s.strip()) > 10]
                
                file_size = os.path.getsize(file_path) / 1024  # KB
                self.file_info.config(text=f"‚úÖ Y√ºklendi: {os.path.basename(file_path)}\n"
                                          f"Boyut: {file_size:.1f} KB | "
                                          f"C√ºmle: {len(self.loaded_texts)}",
                                     fg=self.colors['success'])
                
                self.log("Dosya ba≈üarƒ±yla y√ºklendi!")
                self.log(f"Toplam {len(self.loaded_texts)} c√ºmle bulundu.")
                
            except Exception as e:
                messagebox.showerror("Hata", f"Model y√ºklenemedi: {str(e)}")
    
    def log(self, message):
        timestamp = datetime.now().strftime('%H:%M:%S')
        self.log_text.insert(tk.END, f"[{timestamp}] {message}\n")
        self.log_text.see(tk.END)
        self.root.update()

    
    def start_training(self):
        if not self.loaded_texts:
            messagebox.showwarning("Uyarƒ±", "L√ºtfen √∂nce bir dosya y√ºkleyin!")
            return
        
        if self.is_training:
            messagebox.showinfo("Bilgi", "Eƒüitim zaten devam ediyor!")
            return
        
        # Eƒüitimi ayrƒ± thread'de ba≈ülat
        training_thread = threading.Thread(target=self.train_model)
        training_thread.daemon = True
        training_thread.start()
    
    def train_model(self):
        self.is_training = True
        self.train_btn.config(state='disabled')
        
        try:
            self.log("=" * 50)
            self.log("üöÄ Eƒüitim ba≈ülƒ±yor...")
            self.log(f"Cihaz: {self.device}")
            self.log(f"Bit: {self.bit_var.get()}")
            self.log(f"Epoch: {self.epoch_var.get()}")
            
            # Tokenizer'ƒ± eƒüit
            self.log("üìù Tokenizer hazƒ±rlanƒ±yor...")
            self.tokenizer.fit(self.loaded_texts)
            vocab_size = len(self.tokenizer.word2idx)
            self.log(f"Kelime hazinesi boyutu: {vocab_size}")
            
            # Dataset olu≈ütur
            dataset = TextDataset(self.loaded_texts, self.tokenizer)
            dataloader = DataLoader(dataset, batch_size=32, shuffle=True)
            
            # Model olu≈ütur
            self.log("ü§ñ Model olu≈üturuluyor...")
            bits = int(self.bit_var.get())
            self.model = MiniTransformer(vocab_size, bits=bits).to(self.device)
            
            # Optimizer ve loss
            optimizer = optim.Adam(self.model.parameters(), lr=0.001)
            criterion = nn.CrossEntropyLoss()
            
            # Eƒüitim d√∂ng√ºs√º
            total_steps = self.epoch_var.get() * len(dataloader)
            current_step = 0
            
            self.model.train()
            for epoch in range(self.epoch_var.get()):
                epoch_loss = 0
                for batch_idx, (inputs, targets) in enumerate(dataloader):
                    inputs = inputs.unsqueeze(1).to(self.device)
                    targets = targets.to(self.device)
                    
                    optimizer.zero_grad()
                    outputs = self.model(inputs)
                    loss = criterion(outputs.squeeze(), targets)
                    loss.backward()
                    optimizer.step()
                    
                    epoch_loss += loss.item()
                    current_step += 1
                    
                    # ƒ∞lerleme g√ºncelle
                    progress = (current_step / total_steps) * 100
                    self.progress_var.set(progress)
                    self.progress_label.config(text=f"Epoch {epoch+1}/{self.epoch_var.get()} - "
                                                   f"Batch {batch_idx+1}/{len(dataloader)}")
                
                avg_loss = epoch_loss / len(dataloader)
                self.log(f"Epoch {epoch+1}: Loss = {avg_loss:.4f}")
            
            self.log("‚úÖ Eƒüitim tamamlandƒ±!")
            self.update_model_stats()
            
            messagebox.showinfo("Ba≈üarƒ±lƒ±", "Model eƒüitimi tamamlandƒ±! Artƒ±k sohbet edebilirsiniz.")
            
        except Exception as e:
            self.log(f"‚ùå Hata: {str(e)}")
            messagebox.showerror("Hata", f"Eƒüitim sƒ±rasƒ±nda hata: {str(e)}")
        
        finally:
            self.is_training = False
            self.train_btn.config(state='normal')
            self.progress_var.set(0)
            self.progress_label.config(text="Hazƒ±r")
    
    def send_message(self):
        if not self.model:
            messagebox.showwarning("Uyarƒ±", "√ñnce bir model eƒüitmeniz gerekiyor!")
            return
        
        user_message = self.message_entry.get().strip()
        if not user_message:
            return
        
        # Kullanƒ±cƒ± mesajƒ±nƒ± g√∂ster
        self.chat_display.insert(tk.END, f"üë§ Sen: {user_message}\n", 'user')
        self.message_entry.delete(0, tk.END)
        
        # Model cevabƒ±
        try:
            response = self.generate_response(user_message)
            self.chat_display.insert(tk.END, f"ü§ñ AI: {response}\n\n", 'ai')
            self.chat_display.see(tk.END)
        except Exception as e:
            self.chat_display.insert(tk.END, f"‚ùå Hata: {str(e)}\n\n", 'error')
    
    def generate_response(self, prompt, max_length=50):
        self.model.eval()
        with torch.no_grad():
            # Prompt'u encode et
            input_ids = torch.tensor([self.tokenizer.encode(prompt, 20)]).to(self.device)
            
            generated = []
            for _ in range(max_length):
                outputs = self.model(input_ids)
                next_token = torch.argmax(outputs[0, -1, :]).item()
                
                if next_token == 3:  # END token
                    break
                
                generated.append(next_token)
                input_ids = torch.cat([input_ids, torch.tensor([[next_token]]).to(self.device)], dim=1)
            
            response = self.tokenizer.decode(generated)
            return response if response else "Hmm, d√º≈ü√ºn√ºyorum..."
    
    def update_model_stats(self):
        if not self.model:
            return
        
        total_params = sum(p.numel() for p in self.model.parameters())
        trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
        model_size = total_params * 4 / (1024 * 1024)  # MB
        
        stats_info = f"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë         MODEL ƒ∞STATƒ∞STƒ∞KLERƒ∞          ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë üìä Toplam Parametre: {total_params:,}
‚ïë üéØ Eƒüitilebilir: {trainable_params:,}
‚ïë üíæ Model Boyutu: ~{model_size:.2f} MB
‚ïë üî¢ Quantization: {self.bit_var.get()}-bit
‚ïë üìö Kelime Sayƒ±sƒ±: {len(self.tokenizer.word2idx)}
‚ïë üñ•Ô∏è Cihaz: {self.device}
‚ïë ‚è∞ Son Eƒüitim: {datetime.now().strftime('%H:%M:%S')}
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
        """
        
        self.stats_text.delete(1.0, tk.END)
        self.stats_text.insert(1.0, stats_info)
    
    def save_model(self):
        if not self.model:
            messagebox.showwarning("Uyarƒ±", "Kaydedilecek model yok!")
            return
        
        file_path = filedialog.asksaveasfilename(
            defaultextension=".pth",
            filetypes=[("PyTorch Model", "*.pth")]
        )
        
        if file_path:
            torch.save({
                'model_state': self.model.state_dict(),
                'tokenizer': self.tokenizer.word2idx,
                'config': {
                    'vocab_size': len(self.tokenizer.word2idx),
                    'bits': int(self.bit_var.get())
                }
            }, file_path)
            
            messagebox.showinfo("Ba≈üarƒ±lƒ±", "Model kaydedildi!")
            self.log(f"Model kaydedildi: {file_path}")
    
    def load_model(self):
        file_path = filedialog.askopenfilename(
            filetypes=[("PyTorch Model", "*.pth")]
        )
        
        if file_path:
            try:
                checkpoint = torch.load(file_path, map_location=self.device)
                
                # Tokenizer'ƒ± y√ºkle
                self.tokenizer.word2idx = checkpoint['tokenizer']
                self.tokenizer.idx2word = {v: k for k, v in checkpoint['tokenizer'].items()}
                
                # Model'i olu≈ütur ve y√ºkle
                config = checkpoint['config']
                self.model = MiniTransformer(config['vocab_size'], bits=config['bits']).to(self.device)
                self.model.load_state_dict(checkpoint['model_state'])
                
                self.bit_var.set(str(config['bits']))
                
                messagebox.showinfo("Ba≈üarƒ±lƒ±", "Model y√ºklendi!")
                self.log(f"Model y√ºklendi: {file_path}")
                self.update_model_stats()
                
            except Exception as e:
                messagebox.showerror("Hata", f"Dosya y√ºklenemedi: {str(e)}")

def main():
    root = tk.Tk()
    app = AITrainerApp(root)
    root.mainloop()

if __name__ == "__main__":
    main()
